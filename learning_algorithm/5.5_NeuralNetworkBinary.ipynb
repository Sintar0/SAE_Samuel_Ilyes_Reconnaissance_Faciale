{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84f51b2b",
   "metadata": {},
   "source": [
    "\n",
    "# Reconnaissance faciale via un réseau de neuron \n",
    "\n",
    "## Partie 2: Reconnaissance faciale en temps réel (classification binaire \"admis\"/\"non-admis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb3d054",
   "metadata": {},
   "source": [
    "## Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b2f2e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.neural_network import MLPClassifier # Importation du multi-layer perceptron via la librairie scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfbac10",
   "metadata": {},
   "source": [
    "## Algorithme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8d4b3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of visages matrix -->  (30, 50, 50, 3)\n"
     ]
    }
   ],
   "source": [
    "# Variable vers le dataset\n",
    "DATASET_BINAIRE = \"../dataset/data_binary_classification/\"\n",
    "\n",
    "with open(DATASET_BINAIRE+'/targets.pkl', 'rb') as fh:\n",
    "    targets = pickle.load(fh)\n",
    "\n",
    "with open(DATASET_BINAIRE+'/features.pkl', 'rb') as fh:\n",
    "    features = pickle.load(fh)\n",
    "\n",
    "print('Shape of visages matrix --> ', features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42790305",
   "metadata": {},
   "source": [
    "# Réseau de neuron multi-couche\n",
    "\n",
    "## Définition et paramètre de l'algorithme\n",
    "\n",
    "Le réseau de neurones multi-couches (MLP) est un type de réseau de neurones artificiels qui est composé de plusieurs couches de neurones, avec des connexions entre les neurones de couches adjacentes. Chaque neurone est connecté à tous les neurones de la couche précédente et de la couche suivante. Les neurones de la première couche sont les entrées du réseau, et les neurones de la dernière couche sont les sorties du réseau. Les couches intermédiaires sont appelées couches cachées.\n",
    "\n",
    "Les paramètres $w$ et $b$ désignent respectivement les poids et les biais des connexions entre les neurones. \n",
    "\n",
    "- Les poids $w$ sont utilisés pour multiplier les entrées des neurones\n",
    "\n",
    "- Les biais $b$ sont utilisés pour ajouter un terme constant aux entrées des neurones. \n",
    "\n",
    "Les poids et les biais sont ajustés par l'algorithme d'apprentissage du réseau de neurones pour minimiser l'erreur entre les sorties du réseau et les étiquettes des visages.\n",
    "\n",
    "## Structure de l'algorithme d'apprentissage \n",
    "\n",
    "L'algorithme d'apprentissage du MLP est basé sur la rétro-propagation de l'erreur. L'algorithme d'apprentissage calcule l'erreur entre les sorties du réseau et les étiquettes des visages, et ajuste les poids et les biais des connexions entre les neurones pour minimiser cette erreur.\n",
    "\n",
    "L'algorithme d'apprentissage utilise la dérivée de l'erreur par rapport aux poids et aux biais pour ajuster les poids et les biais des connexions entre les neurones.\n",
    "\n",
    "La fonction d'agrégation est utilisée pour combiner les entrées des neurones en une sortie du réseau. Elle est appliquée à la somme pondérée des entrées des neurones, et produit la sortie du neurone.\n",
    "\n",
    "La fonction d'activation est utilisée pour introduire une non-linéarité dans le réseau de neurones. La fonction d'activation est appliquée à la sortie de la fonction d'agrégation, et produit la sortie du neurone. La fonction d'activation est généralement une fonction non linéaire, telle que la fonction sigmoïde ou la fonction tangente hyperbolique.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "279bc064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "On entraine ici un réseau de neurones pour la reconnaissance de visages\n",
    "paramètres du réseau de neurones:\n",
    "- 2 couches cachées de 128 neurones\n",
    "- 40 itérations\n",
    "- solver: descente de gradient stochastique\n",
    "- taille du batch: 64 (nombre d'images à traiter en même temps)\n",
    "\"\"\"\n",
    "\n",
    "N = len(targets)\n",
    "\n",
    "features = features.reshape(N, -1)\n",
    "\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes = (128, 128),\n",
    "    batch_size = 64,\n",
    "    max_iter = 40,\n",
    "    solver = \"sgd\"\n",
    ")\n",
    "\n",
    "mlp = MLPClassifier()\n",
    "mlp.fit(features, targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5713d005",
   "metadata": {},
   "source": [
    "## Exécution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03952133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'token': False}\n"
     ]
    }
   ],
   "source": [
    "# On importe coordonées des visages\n",
    "cascade_visage = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "camera = cv2.VideoCapture(0) # 0 pour 'built-in' caméra, 1 pour caméra externe\n",
    "authentifications = [] # Liste pour stocker les résultats de l'authentification\n",
    "while True:\n",
    "    \n",
    "    ret, trame = camera.read()\n",
    "    if ret == True:\n",
    "        \n",
    "        gris = cv2.cvtColor(trame, cv2.COLOR_BGR2GRAY)\n",
    "        coordonnees_visage = cascade_visage.detectMultiScale(gris, 1.3, 5)\n",
    "\n",
    "        for (x, y, l, h) in coordonnees_visage:\n",
    "            \n",
    "            visage = trame[y:y + h, x:x + l, :]\n",
    "            visage_redimensionne = cv2.resize(visage, (50, 50)).flatten().reshape(1,-1)\n",
    "            \n",
    "            texte = mlp.predict(visage_redimensionne).astype(str)\n",
    "            \n",
    "\n",
    "\n",
    "            if texte[0] == '0':\n",
    "                authentifications.append(0) # On stocke le résultat de l'authentification dans la liste\n",
    "                texte[0] = 'Non Admis'\n",
    "                cv2.putText(trame, texte[0], (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                cv2.rectangle(trame, (x, y), (x + l, y + l), (0, 0, 255), 2)\n",
    "            else:\n",
    "                authentifications.append(1)\n",
    "                texte[0] = 'Admis'\n",
    "                cv2.putText(trame, texte[0], (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                cv2.rectangle(trame, (x, y), (x + l, y + l), (10, 255, 10), 2)\n",
    "      \n",
    "\n",
    "        cv2.imshow('Reconnaissance faciale en temps réel via un MLP', trame)\n",
    "        \n",
    "        if cv2.waitKey(1) == 27 or len(authentifications) >= 100:\n",
    "            cv2.destroyAllWindows()\n",
    "            camera.release()\n",
    "            break\n",
    "\n",
    "\n",
    "if sum(authentifications) / len(authentifications) > 0.8: # Si plus de 80% des résultats sont positifs, on renvoie un token d'authentification OK\n",
    "    print({\"token\": True})\n",
    "else:\n",
    "    print({\"token\": False}) # Sinon, on renvoie un token d'authentification NOK\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
